{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Besynnjg_Cg9"
      },
      "source": [
        "## **XÂY DỰNG HỆ THỐNG SỬ DỤNG KỸ THUẬT RAG CƠ BẢN**\n",
        "\n",
        "Cài đặt các gói và thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow\n",
        "!pip install llama-index\n",
        "!pip install ragas\n",
        "!pip install datasets\n",
        "\n",
        "!pip install llama-index-llms-langchain\n",
        "!pip install langchainhub\n",
        "!pip install llama-index-llms-fireworks\n",
        "\n",
        "!pip install llama-index-llms-anyscale\n",
        "!pip install llama-index-embeddings-anyscale\n",
        "\n",
        "!pip install anyscale\n",
        "!pip install openai\n",
        "!pip install llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "id": "VPoMOsoCFkV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1NdWoBI_OFR"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.llms.anyscale import Anyscale\n",
        "\n",
        "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
        "from llama_index.core.query_engine import TransformQueryEngine\n",
        "\n",
        "from llama_index.core import PromptTemplate\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from langchain import hub\n",
        "from llama_index.core.prompts import LangchainPromptTemplate\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GocbeIV3rQYc"
      },
      "source": [
        "Thiết lập các khoá API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['ANYSCALE_API_KEY'] = #ANYSCALE_API_KEY\n",
        "os.environ['OPENAI_API_KEY'] = #OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "xPx3TNMTN0_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7_DxX6xKUbH"
      },
      "source": [
        "Tải lên và thực hiện nhúng dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "\n",
        "service_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-3.5-turbo\"),\n",
        "                                               embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "EB-McWJCFh0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tạo công cụ truy vấn với `top_k = 5`"
      ],
      "metadata": {
        "id": "zDpz6IKRDRF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=5)"
      ],
      "metadata": {
        "id": "cpsdbXHPSV82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CÀI ĐẶT KỸ THUẬT PROMPT ENGINEERING**\n",
        "\n",
        "Định nghĩa hàm xem lời nhắc"
      ],
      "metadata": {
        "id": "MDnHnbgiD9jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_prompt_dict(prompts_dict):\n",
        "    for k, p in prompts_dict.items():\n",
        "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
        "        display(Markdown(text_md))\n",
        "        print(p.get_template())\n",
        "        display(Markdown(\"<br><br>\"))"
      ],
      "metadata": {
        "id": "4KTjONGSSm_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cài đặt kỹ thuật Few-shot prompting"
      ],
      "metadata": {
        "id": "SpbVpA8bEtsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.schema import TextNode\n",
        "\n",
        "few_shot_nodes = []\n",
        "for line in open(\"/content/huongdan.json\", \"r\"):\n",
        "    few_shot_nodes.append(TextNode(text=line))\n",
        "\n",
        "few_shot_index = VectorStoreIndex(few_shot_nodes)\n",
        "few_shot_retriever = few_shot_index.as_retriever(similarity_top_k=5)"
      ],
      "metadata": {
        "id": "g9hD6DgES1Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def few_shot_examples_fn(**kwargs):\n",
        "    query_str = kwargs[\"query_str\"]\n",
        "    retrieved_nodes = few_shot_retriever.retrieve(query_str)\n",
        "\n",
        "    result_strs = []\n",
        "    for n in retrieved_nodes:\n",
        "        raw_dict = json.loads(n.get_content())\n",
        "        query = raw_dict[\"query\"]\n",
        "        response_dict = json.loads(raw_dict[\"response\"])\n",
        "        result_str = f\"\"\"\\\n",
        "Query: {query}\n",
        "Response: {response_dict}\"\"\"\n",
        "        result_strs.append(result_str)\n",
        "    return \"\\n\\n\".join(result_strs)"
      ],
      "metadata": {
        "id": "d3P8BbZZS4Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viết lời nhắc mẫu cho câu hỏi"
      ],
      "metadata": {
        "id": "Xoq2NXqTFEPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write prompt template with functions\n",
        "qa_prompt_tmpl_str = \"\"\"\\\n",
        "Trả lời câu hỏi sau về thông tin các trường đại học thành viên thuộc khối Đại học Quốc Gia TP. Hồ Chí Minh dựa trên thông tin ngữ cảnh được cung cấp.\n",
        "Thông tin ngữ cảnh dưới đây.\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "\n",
        "Query: {query_str}.\n",
        "Trả lời: \\\n",
        "\"\"\"\n",
        "\n",
        "def get_context():\n",
        "    relevant_docs = [doc for doc in documents]\n",
        "    return \"\\n\".join([doc.text for doc in relevant_docs])\n",
        "\n",
        "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)"
      ],
      "metadata": {
        "id": "jGHU77_IS7XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_tmpl})"
      ],
      "metadata": {
        "id": "OmwSJhL8S9pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_prompt_dict(query_engine.get_prompts())"
      ],
      "metadata": {
        "id": "pT7dkKQsFeMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CÀI ĐẶT PHƯƠNG PHÁP HYDE**"
      ],
      "metadata": {
        "id": "B3uiuKFjFyCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyde = HyDEQueryTransform(include_original=True)\n",
        "query_engine = TransformQueryEngine(query_engine, hyde)"
      ],
      "metadata": {
        "id": "JCjEAFokf4Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPYx0ycS_x9B"
      },
      "source": [
        "## **THỰC NGHIỆM VÀ ĐÁNH GIÁ**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải lên tập đánh giá"
      ],
      "metadata": {
        "id": "uNKMjxiNPisL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = r'/content/testset.xlsx'\n",
        "test = pd.read_excel(file_path)\n",
        "\n",
        "print(test)"
      ],
      "metadata": {
        "id": "wC7BVkT-Pod9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DASWB37Os1mX"
      },
      "outputs": [],
      "source": [
        "questions = test[\"question\"].to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thí nghiệm 1: Đánh giá hệ thống sử dụng RAG\n",
        "kết hợp GPT-3.5 Turbo**"
      ],
      "metadata": {
        "id": "8YkEi3WFKmCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-3.5-turbo\"),\n",
        "                                               embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "query_engine = index.as_query_engine(similarity_top_k=5)"
      ],
      "metadata": {
        "id": "X5al4e-SLKMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZUyA19W8pYj"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for i in questions:\n",
        "  response_vector = query_engine.query(i)\n",
        "  answers.append(response_vector)\n",
        "  contexts.append([a.get_text() for a in response_vector.source_nodes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7Idl-7fs6RS"
      },
      "outputs": [],
      "source": [
        "ground_truths = [[a] for a in test[\"ground_truth\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTc5XZJ_ImYP"
      },
      "outputs": [],
      "source": [
        "for num, i in enumerate(ground_truths):\n",
        "    if type(i) != str:\n",
        "        ground_truths[num] = str(i)\n",
        "\n",
        "answers = [str(i) for i in answers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8K35VwQImYR"
      },
      "outputs": [],
      "source": [
        "datasample = {\n",
        "    \"question\": questions,\n",
        "    \"contexts\": contexts,\n",
        "    \"answer\": answers,\n",
        "    \"ground_truth\": ground_truths\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(datasample)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cài đặt thư viện đánh giá"
      ],
      "metadata": {
        "id": "rjxdC4C3PrzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJs1lu5LtAYl"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas import evaluate\n",
        "\n",
        "result1 = evaluate(dataset=dataset, metrics=metrics, is_async=True, raise_exceptions=False)\n",
        "\n",
        "print(result1)"
      ],
      "metadata": {
        "id": "uGnGDvQrL14j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rs1 = result1.to_pandas()\n",
        "rs1.head()"
      ],
      "metadata": {
        "id": "0EuchrVjL4DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thí nghiệm 2: Đánh giá hệ thống sử dụng RAG kết hợp GPT-3.5 Turbo và Prompt Engineering**"
      ],
      "metadata": {
        "id": "3BTsNaiEL-Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_tmpl})"
      ],
      "metadata": {
        "id": "LOEQdiLbMA3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for i in questions:\n",
        "  response_vector = query_engine.query(i)\n",
        "  answers.append(response_vector)\n",
        "  contexts.append([a.get_text() for a in response_vector.source_nodes])"
      ],
      "metadata": {
        "id": "b2lfdUmINULE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truths = [[a] for a in test[\"ground_truth\"]]"
      ],
      "metadata": {
        "id": "9UP03qDCNnhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num, i in enumerate(ground_truths):\n",
        "    if type(i) != str:\n",
        "        ground_truths[num] = str(i)\n",
        "\n",
        "answers = [str(i) for i in answers]"
      ],
      "metadata": {
        "id": "263oi36ONqg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasample = {\n",
        "    \"question\": questions,\n",
        "    \"contexts\": contexts,\n",
        "    \"answer\": answers,\n",
        "    \"ground_truth\": ground_truths\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(datasample)"
      ],
      "metadata": {
        "id": "cTHOl6jzNrGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = evaluate(dataset=dataset, metrics=metrics, is_async=True, raise_exceptions=False)\n",
        "\n",
        "rs2 = result2.to_pandas()\n",
        "rs2.head()"
      ],
      "metadata": {
        "id": "wthXSS6iNwa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thí nghiệm 3: Đánh giá hệ thống sử dụng RAG kết hợp GPT-3.5 Turbo và HyDE**"
      ],
      "metadata": {
        "id": "lH7O57imN2RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyde = HyDEQueryTransform(include_original=True)\n",
        "query_engine = TransformQueryEngine(query_engine, hyde)"
      ],
      "metadata": {
        "id": "rZ8Aa31EN1tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=5)"
      ],
      "metadata": {
        "id": "2khhX0S1OHdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for i in questions:\n",
        "  response_vector = query_engine.query(i)\n",
        "  answers.append(response_vector)\n",
        "  contexts.append([a.get_text() for a in response_vector.source_nodes])"
      ],
      "metadata": {
        "id": "oLV-Oo6aOH6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truths = [[a] for a in test[\"ground_truth\"]]"
      ],
      "metadata": {
        "id": "m-xfQvnIOL0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num, i in enumerate(ground_truths):\n",
        "    if type(i) != str:\n",
        "        ground_truths[num] = str(i)\n",
        "\n",
        "answers = [str(i) for i in answers]"
      ],
      "metadata": {
        "id": "NUBbHjPyOMTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasample = {\n",
        "    \"question\": questions,\n",
        "    \"contexts\": contexts,\n",
        "    \"answer\": answers,\n",
        "    \"ground_truth\": ground_truths\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(datasample)"
      ],
      "metadata": {
        "id": "aPUUWdykON87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result3 = evaluate(dataset=dataset, metrics=metrics, is_async=True, raise_exceptions=False)\n",
        "\n",
        "rs3 = result3.to_pandas()\n",
        "rs3.head()"
      ],
      "metadata": {
        "id": "qAmEJQFtOP16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thí nghiệm 4: Đánh giá hệ thống sử dụng RAG kết hợp Mixral 8x7B và Prompt Engineering**"
      ],
      "metadata": {
        "id": "5TJ0S7pbOXZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(llm=Anyscale(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"),\n",
        "                                               embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "query_engine = index.as_query_engine(similarity_top_k=5)"
      ],
      "metadata": {
        "id": "TARQfyIlK8Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_tmpl})"
      ],
      "metadata": {
        "id": "dy8dZlVbOSV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for i in questions:\n",
        "  response_vector = query_engine.query(i)\n",
        "  answers.append(response_vector)\n",
        "  contexts.append([a.get_text() for a in response_vector.source_nodes])"
      ],
      "metadata": {
        "id": "-U432skrOkw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truths = [[a] for a in test[\"ground_truth\"]]"
      ],
      "metadata": {
        "id": "JygUJr-eOnZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num, i in enumerate(ground_truths):\n",
        "    if type(i) != str:\n",
        "        ground_truths[num] = str(i)\n",
        "\n",
        "answers = [str(i) for i in answers]"
      ],
      "metadata": {
        "id": "Cfyh8HGgOqoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasample = {\n",
        "    \"question\": questions,\n",
        "    \"contexts\": contexts,\n",
        "    \"answer\": answers,\n",
        "    \"ground_truth\": ground_truths\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(datasample)"
      ],
      "metadata": {
        "id": "3Ttfj7evOtfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07UN9hONx1R-"
      },
      "outputs": [],
      "source": [
        "result4 = evaluate(dataset=dataset, metrics=metrics, is_async=True, raise_exceptions=False)\n",
        "\n",
        "rs4 = result4.to_pandas()\n",
        "rs4.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thí nghiệm 5: Đánh giá hệ thống sử RAG kết hợp Mixtral 8x7B và HyDE**"
      ],
      "metadata": {
        "id": "pYs-xyb3Ovrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyde = HyDEQueryTransform(include_original=True)\n",
        "query_engine = TransformQueryEngine(query_engine, hyde)"
      ],
      "metadata": {
        "id": "rcOKc0I3O1kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=5)"
      ],
      "metadata": {
        "id": "eZg_daF5O4XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for i in questions:\n",
        "  response_vector = query_engine.query(i)\n",
        "  answers.append(response_vector)\n",
        "  contexts.append([a.get_text() for a in response_vector.source_nodes])"
      ],
      "metadata": {
        "id": "VyL6Td_CO-Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truths = [[a] for a in test[\"ground_truth\"]]"
      ],
      "metadata": {
        "id": "syLbi_znO-h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num, i in enumerate(ground_truths):\n",
        "    if type(i) != str:\n",
        "        ground_truths[num] = str(i)\n",
        "\n",
        "answers = [str(i) for i in answers]"
      ],
      "metadata": {
        "id": "sITJnqTaPAqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasample = {\n",
        "    \"question\": questions,\n",
        "    \"contexts\": contexts,\n",
        "    \"answer\": answers,\n",
        "    \"ground_truth\": ground_truths\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(datasample)"
      ],
      "metadata": {
        "id": "mo91NbAUPDZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result5 = evaluate(dataset=dataset, metrics=metrics, is_async=True, raise_exceptions=False)\n",
        "\n",
        "rs5 = result5.to_pandas()\n",
        "rs5.head()"
      ],
      "metadata": {
        "id": "Pw_AFjgyPD1w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}